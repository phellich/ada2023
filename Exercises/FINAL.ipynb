{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline # to plot in notebook\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * The Collections library is your friend when using dictionaries\n",
    " * Collections library is your friend, for counting multiple objects\n",
    " * Reading files should be done with the following construct  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data/'\n",
    "COUNTRIES_DATASET = DATA_FOLDER+\"happiness2020.csv\"\n",
    "\n",
    "with open('file', 'r') as file:\n",
    "    print(file.read())\n",
    "\n",
    "# Read a csv\n",
    "countries = pd.read_csv(COUNTRIES_DATASET, decimal=',', sep=',', header=1, skiprows=0)\n",
    "\n",
    "# Read a tsv.gz\n",
    "edges = pd.read_table(\"data/links_task-B.tsv.gz\")\n",
    "paths = pd.read_csv('data/paths_df_task-B.tsv.gz', sep=\"\\t\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "my_dict = {}\n",
    "G=nx.Graph()\n",
    "def some_function():\n",
    "    return 0\n",
    "\n",
    "# Usefull functions\n",
    "df.ffill(axis=0, inplace=True)\n",
    "df.dropna(inplace=True, axis=0)\n",
    "\n",
    "df.fillna(value=None, method=None, axis=None, inplace=False)\n",
    "values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "df.fillna(value=values) # Replace all NaN elements in column ‘A’, ‘B’, ‘C’, and ‘D’, with 0, 1, 2, and 3 respectively.\n",
    "\n",
    "df.rename(columns={0:'line_', 1:'scene', 2:'serie_episode'}, inplace=True)\n",
    "df[['serie','episode']] = df.apply(lambda line: line['serie_episode'].split(\"Episode\", 1), result_type='expand', axis=1)\n",
    "script = pd.concat([df, df], axis='columns').drop([\"serie_episode\", \"line_\"], axis=1)\n",
    "\n",
    "df = pd.get_dummies(df) # pandas.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF.LOC\n",
    "df.set_index('channel', inplace=True)                   # Set 'channel' as the index to use loc\n",
    "channel_category = df.loc['PewDiePie', 'channel_cat']   # output just the name\n",
    "\n",
    "# inverse a dictionary\n",
    "index_to_channel = dict((v, k) for k, v in my_dict.items())\n",
    "index_to_cat = dict((k, df.loc[v,'channel_cat']) for k, v in index_to_channel.items())\n",
    "\n",
    "# iterate to create a vector with a if without else + DICTIONNARY\n",
    "array = [x for x in channel_cats if channel_cats[x] == category]\n",
    "array = [(x['SRC'], x['TGT']) for i, x in df.iterrows()]\n",
    "dict_edges_with_att = {(x['SRC'], x['TGT']): x['VOT_RND'] for i, x in df.iterrows()}\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "data = {k: v for k, v in sorted(degree_centrality.items(), key=lambda item: item[1])}\n",
    "\n",
    "# dict without a key\n",
    "my_dict.get('key', 0) # or None\n",
    "eigenvector_centrality = pd.Series(dict(nx.algorithms.eigenvector_centrality(G)))\n",
    "in_degree = pd.Series(dict(G.in_degree()))\n",
    "df_cent = pd.DataFrame([eigenvector_centrality, in_degree]).T.rename({0: \"eigenvector_centrality\",\n",
    "                                                                      1: \"in_degree\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sorted flights for that day\n",
    "flights = df[(df['day'] == 1) & (df['airport'] == 2)] # 2 cond to filter df, with an AND \n",
    "flights = df[(df['day'] == 1) | (df['airport'] == 2)] # 2 cond to filter df, with an OR \n",
    "flights = flights.sort_values('hour')[['flight_id', 'dest_id']]\n",
    "\n",
    "# smart ways to create lists\n",
    "my_list = [10*x+1 for x in range(10)]\n",
    "\n",
    "# agg function to get stats on some col\n",
    "result = df.agg(['std', 'sum', 'mean'])\n",
    "result = df.agg({'A': ['sum', 'min'], 'B': 'max'}) # diff stats on diff col\n",
    "\n",
    "# groupby example\n",
    "df.groupby(df.name).seg_length.sum().sort_values(ascending=False, inplace=False).head()\n",
    "df.join(df).assign(avg_views=lambda x: x['view_count']/x['channel'])[['avg_views']].\\\n",
    "                                plot(kind='bar')\n",
    "\n",
    "# The concat() function (in the main pandas namespace) does all of the heavy lifting of performing concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.\n",
    "# DataFrame.join() is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame\n",
    "# Prefer merge to join, because join is for index-related work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter # returns a hashable dict \n",
    "element_counts = Counter(['apple', 'banana', 'apple', 'orange', 'banana', 'apple'])\n",
    "character_counts = Counter(\"hello world\") \n",
    "# Dictionary: If a dictionary is provided, it counts the frequency of each value. If you want to count keys, you can directly convert the dictionary keys to a list or an iterable.\n",
    "# Set: With a set, it will count the frequency of each element, but since sets do not contain duplicates, each element will have a count of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "letters = ['a', 'b', 'c']\n",
    "zipped = zip(numbers, letters) \n",
    "# list(zipped) = [(1, 'a'), (2, 'b'), (3, 'c')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot with two series on the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(indegree, label=\"yoooooo\")\n",
    "plt.plot(outdegree, label=\"yoooooo\")\n",
    "plt.xlabel(\"yoooooo\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin the data in x and count the number of values in each bin\n",
    "# If the data has already been binned and counted, use bar or stairs to plot the distribution:\n",
    "\n",
    "# we use pandas wrapper\n",
    "df['col'].hist(bins = 100)\n",
    "\n",
    "# alternatively, we can use matplotlib directly\n",
    "plt.hist(df['col'].values, bins = 100)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('yooooo')\n",
    "plt.ylabel('yooooo')\n",
    "plt.title('yooooo');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar (histo with two values, x and height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = df['topic'].value_counts()\n",
    "topic_dist.plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(x=df.index, height=df.title)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('videos')\n",
    "\n",
    "# horizontal bar with error\n",
    "sqrt_N = df['total_posts'].apply(lambda r: math.sqrt(r))\n",
    "s = df['posts_length_stddev']\n",
    "df['ci99'] = 2.576*(s / sqrt_N)\n",
    "\n",
    "plt.barh(df.subreddit, df.posts_length, xerr=df.ci99)\n",
    "plt.xlabel('Post length average (CI 99%)')\n",
    "plt.ylabel('Subreddit')\n",
    "plt.title('Average posts length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['col'])\n",
    "plt.xticks([])\n",
    "plt.title('TITLE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot (2 variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['col1'], df['col2'], s = 2, alpha=0.2)\n",
    "plt.xlabel('yoooooo')\n",
    "plt.ylabel('yoooooo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros((5, 5))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        f = some_function(G, i, j)\n",
    "        heatmap[i][j]=f\n",
    "\n",
    "sns.heatmap(heatmap, annot=True)\n",
    "plt.ylabel(\"yoooooo\")\n",
    "plt.xlabel(\"yoooooo\")\n",
    "plt.title(\"yoooooo\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointplot (comparer selon les categories de x la valeur de y) (corr exam2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15, 5))\n",
    "sns.pointplot(x=\"finished\", y=\"eigenvector_centrality_target\", data=paths, ax=axs[0])\n",
    "sns.pointplot(x=\"finished\", y=\"in_degree_target\", data=paths, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errorbar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_year = df.groupby(df['year']).apply(lambda x: pd.Series({\n",
    "        'average_worldwide_gross': x['worldwide_gross'].mean(),\n",
    "        'std_dev_worldwide_gross': x['worldwide_gross'].std()\n",
    "    }))\n",
    "plt.errorbar(df.index, df.average_worldwide_gross,\n",
    "             yerr = df.std_dev_worldwide_gross,\n",
    "             capsize= 3)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('yoooo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log histogram and logog hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_100 = plt.hist(df['col'], bins=100,log=True, histtype='step')\n",
    "plt.ylabel(\"yoooooo\")\n",
    "plt.xlabel(\"yoooooo\")\n",
    "plt.title(\"yoooooo\")\n",
    "plt.show()\n",
    "\n",
    "plt.loglog(array_100[1][1:],array_100[0])\n",
    "plt.ylabel(\"yoooooo\")\n",
    "plt.xlabel(\"yoooooo\")\n",
    "plt.title(\"yoooooo\")\n",
    "plt.show()\n",
    "\n",
    "df.plot.hist(column=[\"Frequency\"], loglog=True, bins=np.logspace(0, 6, 100),\n",
    "                           title=\"yooooooooo (loglog scale)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal \n",
    "fig, axs = plt.subplots(1, 3, figsize=(12,3))\n",
    "\n",
    "tmp_a = df.count().reset_index().groupby(\"YEA\").VOT.count() \n",
    "axs[0].plot(tmp_a ) \n",
    "axs[0].scatter(tmp_a.index, tmp_a) \n",
    "axs[0].set_title(\"a) # RfA\")\n",
    "axs[0].set_xlabel(\"Year\")\n",
    "print(\"a) # RfA 2008:\", tmp_a.loc[2008])\n",
    "\n",
    "tmp_b = df.groupby([\"YEA\"]).VOT.apply(lambda x: np.mean(x > 0))\n",
    "axs[1].plot(tmp_b ) \n",
    "axs[1].scatter(tmp_b.index, tmp_b) \n",
    "axs[1].set_title(\"b) % Positive votes\")\n",
    "axs[1].set_xlabel(\"Year\")\n",
    "print(\"b) % Positive votes:\", tmp_b.loc[2008])\n",
    "\n",
    "tmp_c = df.count().reset_index().groupby(\"YEA\").VOT.mean()\n",
    "axs[2].plot(tmp_c ) \n",
    "axs[2].scatter(tmp_c.index, tmp_c) \n",
    "axs[2].set_title(\"c) Avg. # votes per RfA\")\n",
    "axs[2].set_xlabel(\"Year\");\n",
    "\n",
    "# Vertical \n",
    "fig, axs = plt.subplots(3, sharex=True)\n",
    "axs[0].plot(tmp_a)\n",
    "axs[0].set_title(\"count_rfa_by_year\")\n",
    "axs[1].plot(tmp_b)\n",
    "axs[1].set_title(\"frac_pos_votes_by_year\")\n",
    "axs[1].set_ylim([0, 1])\n",
    "axs[2].plot(tmp_c)\n",
    "axs[2].set_title(\"avg_vote_count_by_year_and_rfa\")\n",
    "plt.xlabel(\"Year\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complementary continous ditribution function CCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(list(dict(G.degree()).values()), complementary=True)\n",
    "plt.xscale(\"log\")\n",
    "plt.axvline(10) # plot vertical line \n",
    "plt.axhline(0.4)\n",
    "plt.title(\"ComplementaryCDF\")\n",
    "plt.xlabel(\"Degree_centrality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gros petage de cable, matrice de subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (15,10),gridspec_kw={'hspace': 0.4, 'wspace': 0.2})\n",
    "fig.suptitle(\"In and out degree distribution of the Wikispeedia Network (Left: linear axes, Right: Log axes)\", fontsize=20)\n",
    "axes[0][0].plot(range(len(in_degree_freq)), in_degree_freq, 'go-', label='In-degree') # list\n",
    "axes[0][1].loglog(range(len(in_degree_freq)), in_degree_freq, 'go-', label='In-degree') \n",
    "axes[1][0].plot(range(len(out_degree_freq)), out_degree_freq, 'bo-', label='Out-degree')\n",
    "axes[1][1].loglog(range(len(out_degree_freq)), out_degree_freq, 'bo-', label='Out-degree')\n",
    "for x in range(0,axes.shape[0]):\n",
    "    for y in range(0,axes.shape[1]):\n",
    "        axes[x,y].set_xlabel('Degree', fontsize = 20)\n",
    "        axes[x,y].set_ylabel('Frequency', fontsize = 20)\n",
    "        axes[x,y].legend(fontsize=15)\n",
    "fig.subplots_adjust(top=0.94)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_set(data_to_split, ratio=0.8):\n",
    "    mask = np.random.rand(len(data_to_split)) < ratio\n",
    "    return [data_to_split[mask].reset_index(drop=True), data_to_split[~mask].reset_index(drop=True)]\n",
    "[train, test] = split_set(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# FIRST OPTION\n",
    "X = df.drop(columns=\"view_count\")\n",
    "y = df[\"view_count\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# SECOND OPTION \n",
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# THIRD OPTION : create numpy arrays\n",
    "X = top5_articles_content['content'].to_numpy()\n",
    "y = top5_articles_content['labels'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC/AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = (df.PP + df.NN >= df.PN).astype(int) # convert boolean to int\n",
    "print(\"A) roc score\", roc_auc_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge_hyper = {'alpha':(0.001, 0.01, 0.1)}\n",
    "ridge_cv = GridSearchCV(ridge, ridge_hyper, cv=3)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "ridge_cv.cv_results_['mean_test_score']\n",
    "\n",
    "mean_absolute_error(y_test, ridge_cv.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF transformation + SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer( max_features=150, stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(df.TXT_PROCESSED.values).toarray()\n",
    "X2 = np.hstack((X, df[[\"PP\", \"NN\", \"PN\", \"N\", \"P\"]].values))\n",
    "y =  (df.VOT == 1).values.astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "clf = SGDClassifier(random_state=0, loss=loss_v).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test)[:,1]\n",
    "print(\"(with predict_proba)\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF matrix + MultiClass Classifier with cross validation CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__alpha': [1e-4],    \n",
    "}\n",
    "\n",
    "text_clf = Pipeline([                   # utility that helps automate machine learning workflows\n",
    "    ('vect', CountVectorizer()),        # converts a collection of text documents to a matrix of token counts\n",
    "    ('tfidf', TfidfTransformer()),      # transforms the count matrix from CountVectorizer to a normalized tf-idf representation\n",
    "    ('clf', SGDClassifier(penalty='l2', loss='log', max_iter=5, tol=None, random_state=42)) # class_weight='balanced'\n",
    "])                                      # linear classifier (SVM, logistic regression, etc.) with SGD training\n",
    "\n",
    "# GridSearchCV is applied to the pipeline with the defined parameters. \n",
    "# It will conduct a grid search over the parameter space using 5-fold cross-validation\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)   # fits the grid search model to the training data\n",
    "\n",
    "# best score achieved across all parameter combinations in the grid search\n",
    "print(gs_clf.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "# grid search object gs_clf is used to make predictions on the test data\n",
    "predicted = gs_clf.predict(X_test)\n",
    "print(\"Accuracy on Test Data: \", np.mean(predicted == y_test))\n",
    "\n",
    "# In a 5-class classification a random model obtains an accuracy of 20% in expectation. \n",
    "# Thus, obtaining an accuracy in high 80s is a strong outcome.\n",
    "\n",
    "# List of top 10 words sorted in descending order of importance based on feature weights earned by the classifier\n",
    "top5_coeff_indices = np.argsort(gs_clf.best_estimator_.named_steps['clf'].coef_)[:,-10:][:,::-1]\n",
    "np.array(gs_clf.best_estimator_.named_steps['vect'].get_feature_names())[top5_coeff_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics of accuracy and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie Applied ML\n",
    "def compute_confusion_matrix(true_label, prediction_proba, decision_threshold=0.5): \n",
    "    \n",
    "    predict_label = (prediction_proba[:,1]>decision_threshold).astype(int)   \n",
    "                                                                                                                       \n",
    "    TP = np.sum(np.logical_and(predict_label==1, true_label==1))\n",
    "    TN = np.sum(np.logical_and(predict_label==0, true_label==0))\n",
    "    FP = np.sum(np.logical_and(predict_label==1, true_label==0))\n",
    "    FN = np.sum(np.logical_and(predict_label==0, true_label==1))\n",
    "    \n",
    "    confusion_matrix = np.asarray([[TP, FP],\n",
    "                                    [FN, TN]])\n",
    "    return confusion_matrix\n",
    "\n",
    "def compute_confusion_mat(true_label, predict_label): \n",
    "                                                                                                                       \n",
    "    TP = np.sum(np.logical_and(predict_label==1, true_label==1))\n",
    "    TN = np.sum(np.logical_and(predict_label==0, true_label==0))\n",
    "    FP = np.sum(np.logical_and(predict_label==1, true_label==0))\n",
    "    FN = np.sum(np.logical_and(predict_label==0, true_label==1))\n",
    "    \n",
    "    confusion_matrix = np.asarray([[TP, FP],\n",
    "                                    [FN, TN]])\n",
    "    return confusion_matrix\n",
    "\n",
    "def compute_all_score(confusion_matrix, t=0.5):\n",
    "    [[TP, FP],[FN, TN]] = confusion_matrix.astype(float)\n",
    "    \n",
    "    accuracy =  (TP+TN)/np.sum(confusion_matrix)\n",
    "    \n",
    "    precision_positive = TP/(TP+FP) if (TP+FP) !=0 else np.nan\n",
    "    precision_negative = TN/(TN+FN) if (TN+FN) !=0 else np.nan\n",
    "    \n",
    "    recall_positive = TP/(TP+FN) if (TP+FN) !=0 else np.nan\n",
    "    recall_negative = TN/(TN+FP) if (TN+FP) !=0 else np.nan\n",
    "\n",
    "    F1_score_positive = 2 *(precision_positive*recall_positive)/(precision_positive+recall_positive) if (precision_positive+recall_positive) !=0 else np.nan\n",
    "    F1_score_negative = 2 *(precision_negative*recall_negative)/(precision_negative+recall_negative) if (precision_negative+recall_negative) !=0 else np.nan\n",
    "\n",
    "    return [t, accuracy, precision_positive, recall_positive, F1_score_positive, precision_negative, recall_negative, F1_score_negative]\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, balanced_accuracy_score\n",
    "\n",
    "confusion_matrix(y_test_small, predicted_small)                 # Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "balanced_accuracy_score(y_test_small, predicted_small)          # The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "                                                                # The best value is 1 and the worst value is 0\n",
    "classification_report(y_test_small, predicted_small, digits=3)  # Build a text report showing the main classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression with cross Validation CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = (1, 10, 100)\n",
    "log_reg_cv = LogisticRegressionCV(Cs=Cs, cv=3, random_state=42, max_iter=200)\n",
    "\n",
    "log_reg_cv.fit(X_train, y_train_binary)\n",
    "opt_C = log_reg_cv.C_[0]\n",
    "opt_C\n",
    "\n",
    "log_reg_cv.scores_[1].mean(axis=0)\n",
    "log_reg_cv.score(X_test, y_test_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression classifier using sklean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = TFIDF_questions\n",
    "y = df[\"gender\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression(C=10, random_state=42, max_iter=2000)\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(s, \":\", \"accuracy\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df[\"VOT2\"] = (df.VOT == 1).values.astype(int)\n",
    "smf.logit(\"VOT2 ~ PP + NN +PN\" , data=df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "mod = smf.ols(formula='time ~ C(high_blood_pressure) * C(DEATH_EVENT,  Treatment(reference=0)) + C(diabetes)',\n",
    "              data=df)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "# PREPARE THE MODEL\n",
    "# - Equations are specified using patsy formula syntax. Important operators are:\n",
    "#     1. `~` : Separates the left-hand side and right-hand side of a formula.\n",
    "#     2. `+` : Creates a union of terms that are included in the model.\n",
    "#     3. `:` : Interaction term.\n",
    "#     3. `*` : `a * b` is short-hand for `a + b + a:b`, and is useful for the common case of wanting to include all interactions between a set of variables.\n",
    "# - Intercepts are added by default.\n",
    "# - Categorical variables can be included directly by adding a term C(a).\n",
    "\n",
    "# ANALYSE THE SUMURY\n",
    "# - The dependent variable : time (number of days at the hospital)\n",
    "# - Method: The type of model that was fitted (OLS)\n",
    "# - Nb observations: The number of datapoints (299 patients)\n",
    "# - R2: The fraction of explained variance\n",
    "# - A list of predictors\n",
    "# - For each predictor: coefficient, standard error of the coefficients, p-value, 95% confidence intervals. We can see that only high blood pressure is a significant predictor (p = 0.001), while diabetes is not (0.584).\n",
    "# - Warnings if there are numerical issues (hopefully not!)\n",
    "\n",
    "# C(diabetes)[T.1]: This coefficient represents the change in the dependent variable for individuals with diabetes (1), compared to those without (0), all else being equal.\n",
    "\n",
    "# si P>|t| > 0.05, alors c'est PAS STATS SIGNIFICANT : on rejette l'hypothese que c'est important\n",
    "# si c'est True/ False => analyse that if it becomes True it gains that amount in that way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Bis. Unsupervised learning : K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "### How to select K in K-Means?  You have a couple of options:\n",
    "\n",
    "# - Silhouette score: Find the K with the desired tradeoff between the number of clusters and cohesion/separation.\n",
    "silhouettes = []\n",
    "\n",
    "# Try multiple k\n",
    "for k in range(2, 11):\n",
    "    # Cluster the data and assigne the labels\n",
    "    labels = KMeans(n_clusters=k, random_state=10).fit_predict(X)\n",
    "    # Get the Silhouette score\n",
    "    score = silhouette_score(X, labels)\n",
    "    silhouettes.append({\"k\": k, \"score\": score})\n",
    "    \n",
    "# Convert to dataframe\n",
    "silhouettes = pd.DataFrame(silhouettes)\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(silhouettes.k, silhouettes.score)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "\n",
    "# - Elbow method: Find the \"elbow\" in the curve of the Sum of Squared Errors\n",
    "def plot_sse(features_X, start=2, end=11):\n",
    "    sse = []\n",
    "    for k in range(start, end):\n",
    "        # Assign the labels to the clusters\n",
    "        kmeans = KMeans(n_clusters=k, random_state=10).fit(features_X)\n",
    "        sse.append({\"k\": k, \"sse\": kmeans.inertia_})\n",
    "\n",
    "    sse = pd.DataFrame(sse)\n",
    "    # Plot the data\n",
    "    plt.plot(sse.k, sse.sse)\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Sum of Squared Errors\")\n",
    "    \n",
    "plot_sse(X)\n",
    "\n",
    "# Plot the results \n",
    "fig, axs = plt.subplots(1, 1, figsize=(4,4), sharey=True)\n",
    "\n",
    "# Plot the clusters with K = 3\n",
    "labels = KMeans(n_clusters=3, random_state=0).fit_predict(X)\n",
    "axs.scatter(X[:,0], X[:,1], c=labels, alpha=0.6)\n",
    "\n",
    "# See notebook for reduced PCA or t-SNE, and DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All graph types (Graph, DiGraph, MultiGraph, MultiDiGraph) and their methods:\n",
    "# https://networkx.org/documentation/stable/reference/classes/index.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of graph !! https://networkx.org/documentation/stable/reference/classes/index.html  \n",
    "G =nx.from_pandas_edgelist(edges, 'ColSource', 'ColTarget', edge_attr=None, create_using= nx.Graph()) \n",
    "nx.set_node_attributes(G, df['Role'].to_dict(), 'Role' )\n",
    "# OR \n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "nx.set_node_attributes(G, betweenness, 'betweenness')\n",
    "\n",
    "# thinks of in degree and out_degree in Di graph and multiDigraph !!!\n",
    "tmp = sorted(dict(G.out_degree()).values())\n",
    "in_degree = pd.Series(dict(G.in_degree()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "edge_list = pd.read_csv(\"./data/part-1/edgelist.tsv\", sep=\"\\t\")\n",
    "node_list = pd.read_csv(\"./data/part-1/nodelist.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Creates node attributes\n",
    "for _, node in node_list.iterrows():\n",
    "    node = dict(node)\n",
    "    G.add_node(node['u'], score=node['score'], name=node['name'])\n",
    "\n",
    "# Creates edge attributes\n",
    "for _, edge in edge_list.iterrows():\n",
    "    edge = dict(edge)\n",
    "    G.add_edge(edge['u'], edge['v'], gender=edge['gender'])\n",
    "\n",
    "for u, v, k in G.edges: # because Multi(Di)Graph !\n",
    "    # do what you want to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_graph(G):\n",
    "    print(G)\n",
    "    print(f\"There are {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    if nx.is_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" %nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" %nx.diameter(G)) # Longest shortest path\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "    print(\"Sparsity: %.4f\" %nx.density(G))  # #edges/#edges-complete-graph\n",
    "    # #closed-triplets(3*#triangles)/#all-triplets\n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" %nx.transitivity(G))\n",
    "\n",
    "def describe_digraph(G):\n",
    "    print(G)\n",
    "    print(f\"There are {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    print(f\"Average in-degree: {sum(d for n, d in G.in_degree()) / float(G.number_of_nodes())}\")\n",
    "    print(f\"Average out-degree: {sum(d for n, d in G.out_degree()) / float(G.number_of_nodes())}\")\n",
    "\n",
    "    if nx.is_strongly_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" % nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" % nx.diameter(G))  # Longest shortest path\n",
    "    else:\n",
    "        print(\"DiGraph is not strongly connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "\n",
    "    print(\"Sparsity: %.4f\" % nx.density(G))  \n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" % nx.transitivity(G))\n",
    "\n",
    "def describe_multigraph(G):\n",
    "    print(G)\n",
    "    print(f\"There are {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "    \n",
    "    if nx.is_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" % nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" % nx.diameter(G))  # Longest shortest path\n",
    "    else:\n",
    "        print(\"MultiGraph is not connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined!\")\n",
    "\n",
    "    print(\"Sparsity: %.4f\" % nx.density(G))  \n",
    "    print(\"Global clustering coefficient aka Transitivity: %.4f\" % nx.transitivity(G))\n",
    "\n",
    "def describe_multidigraph(G):\n",
    "    print(G)\n",
    "    print(f\"There are {G.number_of_nodes()} nodes and {G.size()} edges.\")\n",
    "    print(\"Avg In-Degree: %.4f\" % (sum(d for n, d in G.in_degree()) / float(G.number_of_nodes())))\n",
    "    print(\"Avg Out-Degree: %.4f\" % (sum(d for n, d in G.out_degree()) / float(G.number_of_nodes())))\n",
    "\n",
    "    # Checking for strong connectivity\n",
    "    if nx.is_strongly_connected(G):\n",
    "        print(\"Avg. Shortest Path Length: %.4f\" % nx.average_shortest_path_length(G))\n",
    "        print(\"Diameter: %.4f\" % nx.diameter(G))  # Longest shortest path in a strongly connected component\n",
    "    else:\n",
    "        print(\"MultiDiGraph is not strongly connected\")\n",
    "        print(\"Diameter and Avg shortest path length are not defined for the whole graph!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subgraph view with edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all edges with a specific attribute (filter on value), store their keys, and then create a subgraph with them \n",
    "edges_2004 = [i for i, v in nx.get_edge_attributes(G, \"YEA\").items() if v == 2004]\n",
    "G_2004 = G.edge_subgraph(edges_2004)\n",
    "\n",
    "idx = 0\n",
    "tmp = []\n",
    "for i in nx.enumerate_all_cliques(G_2004):\n",
    "    if len(i) < 3: \n",
    "        continue\n",
    "    if len(i) > 3:\n",
    "        break\n",
    "    idx += 1\n",
    "    tmp.append(i)\n",
    "\n",
    "# Mine\n",
    "df_2004 = df[df['YEA']==2004]\n",
    "edges_of_2004 = [(x['SRC'], x['TGT']) for i, x in df_2004.iterrows()] # create list of tupe, ie list of edges\n",
    "H = nx.edge_subgraph(G, edges_of_2004)\n",
    "cliques = nx.enumerate_all_cliques(H)\n",
    "triangles = list(filter(lambda x: len(x)==3, cliques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indegree and outdegree distributions\n",
    "indegree = []\n",
    "outdegree = []\n",
    "for node in G.nodes:\n",
    "    indegree.append(len(list(G.predecessors(node))))\n",
    "    outdegree.append(len(list(G.successors(node))))\n",
    "indegree = np.array(indegree)\n",
    "outdegree = np.array(outdegree)\n",
    "\n",
    "indegree = np.array(sorted(indegree/sum(indegree), reverse=True)).cumsum()\n",
    "outdegree = np.array(sorted(outdegree/sum(outdegree), reverse=True)).cumsum()\n",
    "# See ecfplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoir le nombre de connected components et leur description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode 1\n",
    "nx.number_connected_components(G)\n",
    "\n",
    "# Methode 2\n",
    "comp = list(nx.connected_components(G))\n",
    "print('The graph contains', len(comp), 'connected components')\n",
    "\n",
    "# Methode 3\n",
    "[len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)] # list the sizes of all connected components in G from the largest to smallest\n",
    "\n",
    "# Analyse a multigraph\n",
    "# Graph.subgraph(nodes)[source] # Returns a SubGraph view of the subgraph induced on nodes.\n",
    "print(nx.is_strongly_connected(G))\n",
    "print(nx.number_strongly_connected_components(G))\n",
    "components = [c for c in sorted(nx.strongly_connected_components(G), key=len, reverse=True)]\n",
    "print(len(components[0]))\n",
    "\n",
    "# Number of nodes and edge in the largest connected component\n",
    "largest_cc = max(nx.weakly_connected_components(G), key=len)\n",
    "H = G.subgraph(list(largest_cc))\n",
    "print(len(H.nodes()), len(H.edges()), len(H.edges())/len(H.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortest path between two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fell_whitehead_path = nx.shortest_path(G, source=\"Margaret Fell\", target=\"George Whitehead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and print betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness = nx.betweenness_centrality(G)\n",
    "nx.set_node_attributes(G, betweenness, 'betweenness')\n",
    "sorted_betweenness = sorted(betweenness.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "for index, bw in sorted_betweenness[:2]:\n",
    "    channel_name = G.nodes[index]['channel']\n",
    "    print(index, 'who is', G.nodes[index]['channel'], 'in category',  G.nodes[index]['category'], 'has betweeness: %.3f' %bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of in_degree/out_degree of a DiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_histogram_directed(G, in_degree=False, out_degree=False):\n",
    "    nodes = G.nodes()\n",
    "    if in_degree:\n",
    "        in_degree = dict(G.in_degree())\n",
    "        degseq=[in_degree.get(k,0) for k in nodes]\n",
    "    elif out_degree:\n",
    "        out_degree = dict(G.out_degree())\n",
    "        degseq=[out_degree.get(k,0) for k in nodes]\n",
    "    else:\n",
    "        degseq=[v for k, v in G.degree()]\n",
    "    dmax=max(degseq)+1\n",
    "    freq= [ 0 for d in range(dmax) ]\n",
    "    for d in degseq:\n",
    "        freq[d] += 1\n",
    "    return freq\n",
    "\n",
    "in_degree_freq = degree_histogram_directed(G, in_degree=True)\n",
    "out_degree_freq = degree_histogram_directed(G, out_degree=True)\n",
    "degrees = range(len(in_degree_freq))\n",
    "# see the petage de cable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataframe from a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = nx.get_edge_attributes(G, \"gender\")\n",
    "df = []\n",
    "for u, v, k in G.edges: #multigraph\n",
    "    df.append(\n",
    "    {   \n",
    "        \"gender\": gender_dict[(u,v,k)] == \"F\",\n",
    "        \"d\": scores_dict[v] - scores_dict[u],\n",
    "        \"q\": scores_dict[u],\n",
    "    }\n",
    "    )\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1e methode\n",
    "def bootstrap95(df):\n",
    "    rocauc_dif=[]\n",
    "    for i in range(200):\n",
    "        df_sampled = df.sample(frac = 1, replace = True)\n",
    "\n",
    "        y_true = df_sampled['VOT']\n",
    "        y_SBT_clas = df_sampled['SBT_clas']\n",
    "        y_weak_SBT_clas = df_sampled['weak_SBT_clas']\n",
    "\n",
    "        val = roc_auc_score(y_true, y_SBT_clas)-roc_auc_score(y_true, y_weak_SBT_clas)\n",
    "        rocauc_dif.append(val.mean())\n",
    "\n",
    "    print(\"95% CI:\", np.quantile( np.array(rocauc_dif), q=[0.025, 0.975]))\n",
    "    return np.quantile( np.array(rocauc_dif), q=[0.025, 0.975])\n",
    "\n",
    "CI_roc_dif = bootstrap95(df)\n",
    "\n",
    "# 2e methode\n",
    "def do_bootstrap(data, n=1000): # 95%\n",
    "    sample_statistic = [] \n",
    "    for _ in range(n):\n",
    "        sampled_data = np.random.choice(data, size=len(data))  \n",
    "        sample_statistic.append(np.mean(sampled_data))\n",
    "    return (np.percentile(sample_statistic, 2.5), np.percentile(sample_statistic, 97.5))\n",
    "\n",
    "do_bootstrap(howto_perchannel_new)\n",
    "\n",
    "# no overlap to have significant one better than another !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mean_F = df[df['gender']=='F']['score_gain']\n",
    "mean_M = df[df['gender']=='M']['score_gain']\n",
    "stats.ttest_ind(mean_F, mean_M)\n",
    "\n",
    "stats.spearmanr(df.similarity, df.ranking) # get correlation!!\n",
    "# If pvalue>0.05, then it has no significant correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average degree is not recommended as the degree distribution of real-world networks usually follows a powerlaw. Summarizing powerlaws with average values is not a good idea, as there is a long tail, and there are many nodes that have very high degree. Instead, median is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are performing classification tasks in spase matrices where the number of features outnumber the number of datapoints. Thus, the lack of regularization can lead to overfitting. When we increase C we decrease the regularization penalty and thus increase overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "reddit = spark.read.json(\"messages.json.gz\")\n",
    "reddit.printSchema()\n",
    "\n",
    "# Process a pyspark dataframe\n",
    "subreddit_info = reddit.groupBy(\"subreddit\")\\\n",
    "    .agg(count(\"*\").alias(\"total_posts\"), \n",
    "         countDistinct(\"author\").alias(\"users_count\"),\n",
    "         avg(length(\"body\")).alias(\"posts_length\"), # get avg len of a string\n",
    "         avg(\"score\")).alias(\"posts_length\"),   # get avg of a score in a col\n",
    "         stddev(length(\"body\")).alias(\"posts_length_stddev\")\n",
    "        ).cache()\n",
    "\n",
    "# Comvert from PySpark dataframe to Panda dataframe\n",
    "by_posts = subreddit_info.select(\"subreddit\", \"total_posts\")\\\n",
    "    .sort(col(\"total_posts\").desc())\\\n",
    "        .limit(50000)\\\n",
    "            .toPandas()\n",
    "\n",
    "# ex 3\n",
    "subreddits_by_pl = subreddit_info.toPandas()\\\n",
    "    .sort_values(\"posts_length\", ascending=False)\\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "# Convert the pandas DataFrame to a PySpark DataFrame\n",
    "spark_df = spark.createDataFrame(pandas_df)\n",
    "\n",
    "# from dataframe df to spark rdd\n",
    "subreddit_50k = filtered_tokens.rdd.map(lambda r: (r.subreddit, [r.word])).reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    for char in EXCLUDE_CHARS:\n",
    "        line = line.replace(char, ' ')\n",
    "    return line.lower()\n",
    "\n",
    "df[\"Line\"] = df[\"Line\"].apply(clean_line)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count nb of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[\"Words\"] = lines[\"Line\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one feature is still very desequlibrate\n",
    "# we should force equilibrate it \n",
    "\n",
    "G = nx.Graph()\n",
    "for control_idx, control_row in df_notreat.iterrows():\n",
    "    for treat_idx, treat_row in df_treat.iterrows():\n",
    "\n",
    "        control_person = pd.DataFrame([control_row])\n",
    "        treated_person = pd.DataFrame([treat_row])\n",
    "        similarity = abs(res.predict(control_person) - res.predict(treated_person))\n",
    "        \n",
    "        if feature1 == feature2: \n",
    "            G.add_weighted_edges_from([(control_row, treat_row, similarity)])\n",
    "\n",
    "# A matching is a subset of edges in which no node occurs more than once. The weight of a matching is the sum of the weights of its edges. A maximal matching cannot add more edges and still be a matching. The cardinality of a matching is the number of matched edges.\n",
    "matching = nx.max_weight_matching(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_obs = nx.Graph()\n",
    "vs = set(list(zip(paths['source'].values, paths['shortest_path_length'].values)))\n",
    "match_set = set()\n",
    "max_counter = len(vs)\n",
    "counter = 0\n",
    "\n",
    "# iterate over a zip of the two features we want to nmatch (en qques sortes)\n",
    "for source, min_dist in vs:\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter/max_counter)\n",
    "\n",
    "    high_indegree = paths[(paths['in_degree_binary_target'] == True) & \n",
    "                     (paths['source'] == source) &\n",
    "                     (paths['shortest_path_length'] == min_dist)]\n",
    "\n",
    "    low_indegree = paths[(paths['in_degree_binary_target'] == False) & \n",
    "                       (paths['source'] == source) &\n",
    "                       (paths['shortest_path_length'] == min_dist)]\n",
    "    \n",
    "    for i, f in zip(high_indegree.index, high_indegree['target']):\n",
    "        for j, u in zip(low_indegree.index, low_indegree['target']):\n",
    "            if f != u:\n",
    "                G_obs.add_edge(i, j)\n",
    "                match_set.add((i,j))\n",
    "\n",
    "# A matching is a subset of edges in which no node occurs more than once. A maximal matching cannot add more edges and still be a matching.\n",
    "matching = nx.maximal_matching(G_obs)\n",
    "print(f'#Matched pairs: {len(matching)}')\n",
    "\n",
    "#\n",
    "high_games_match_cands = {}; low_games_match_cands = {}\n",
    "for (u,v) in match_set:\n",
    "    if u not in high_games_match_cands:\n",
    "        high_games_match_cands[u] = [v]\n",
    "    else:\n",
    "        high_games_match_cands[u].append(v)\n",
    "    if v not in low_games_match_cands:\n",
    "        low_games_match_cands[v] = [u]\n",
    "    else:\n",
    "        low_games_match_cands[v].append(u)\n",
    "\n",
    "# \n",
    "print(len(high_games_match_cands), len(low_games_match_cands))\n",
    "set_low_games_match_cands = set(low_games_match_cands.keys())\n",
    "set_high_games_match_cands = set(high_games_match_cands.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
